{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SNAproject2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXTJZ58B5ZS8sjwpbLQJXD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhytoto12/SNA/blob/master/SNAproject2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPecSVQluxvz",
        "colab_type": "text"
      },
      "source": [
        "# Social Network Analysis project 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAzVr7_vAg5w",
        "colab_type": "text"
      },
      "source": [
        "### install torch_geometric library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZEWcXmHrpCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGGu2aNRpNpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_geometric.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Coiz8MCgAud5",
        "colab_type": "text"
      },
      "source": [
        "### Dataset\n",
        "> 'Cora', 'CiteSeer', 'PubMed'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktqe5yotrTkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = 'Cora'\n",
        "dataset = Planetoid('./data', dataset, transform=T.NormalizeFeatures())\n",
        "data = dataset[0]\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "# class distribution\n",
        "cnt = np.zeros(10)\n",
        "n = data.y[data.test_mask].shape[0]\n",
        "for i in range(n) :\n",
        "  cnt[data.y[data.test_mask][i]] += 1\n",
        "print(cnt)\n",
        "\n",
        "\n",
        "colors = [\n",
        "    '#ffc0cb', '#bada55', '#008080', '#420420', '#7fe5f0', '#065535', '#ffd700'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMZBPZa_A6lB",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "> 'Flickr'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJWFZ_xlCjX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.datasets import Flickr\n",
        "dataset = Flickr('./data')\n",
        "data = dataset[0]\n",
        "cnt = np.zeros(data.num_classes)\n",
        "n = data.y[data.test_mask].shape[0]\n",
        "for i in range(n) :\n",
        "  cnt[data.y[data.test_mask][i]] += 1\n",
        "print(cnt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WpepOMAzSdD",
        "colab_type": "text"
      },
      "source": [
        "## 1. Simple Graph Labeling Technique\n",
        "### 1.1 ICA\n",
        "https://github.com/tkipf/ica/tree/master/ica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GE8EAYjplYv",
        "colab_type": "text"
      },
      "source": [
        "## 2. Node Embedding Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcScnplnpuyJ",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Node2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67MPrpxdzc8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.nn import Node2Vec\n",
        "\n",
        "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=20,\n",
        "                 context_size=10, walks_per_node=10, num_negative_samples=1,\n",
        "                 sparse=True).to(device)\n",
        "\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
        "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for pos_rw, neg_rw in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    z = model()\n",
        "    acc = model.test(z[data.train_mask], data.y[data.train_mask],\n",
        "                     z[data.test_mask], data.y[data.test_mask], max_iter=100)\n",
        "    return acc\n",
        "\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    acc = test()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Acc: {acc:.4f}')\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def plot_points(colors):\n",
        "    model.eval()\n",
        "    z = model(torch.arange(data.num_nodes, device=device))\n",
        "    z = TSNE(n_components=2).fit_transform(z.cpu().numpy())\n",
        "    y = data.y.cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i in range(dataset.num_classes):\n",
        "        plt.scatter(z[y == i, 0], z[y == i, 1], s=20, color=colors[i])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_points(colors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBKiqPTipzA0",
        "colab_type": "text"
      },
      "source": [
        "## 3. GNN technique\n",
        "### 3.1. GCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSF76U7wqBz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_features, 128, cached=True,\n",
        "                             normalize=True)\n",
        "        self.conv2 = GCNConv(128, 16, cached=True,\n",
        "                             normalize=True)\n",
        "        self.conv3 = GCNConv(16, dataset.num_classes, cached=True,\n",
        "                             normalize=True)\n",
        "\n",
        "        self.reg_params = self.conv1.parameters()\n",
        "        self.non_reg_params = self.conv2.parameters()\n",
        "\n",
        "    def forward(self):\n",
        "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index, edge_weight))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv3(x, edge_index, edge_weight)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.reg_params, weight_decay=5e-4),\n",
        "    dict(params=model.non_reg_params, weight_decay=0)\n",
        "], lr=0.005)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "best_val_acc = test_acc = 0\n",
        "for epoch in range(1, 201):\n",
        "    train()\n",
        "    train_acc, val_acc, tmp_test_acc = test()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        test_acc = tmp_test_acc\n",
        "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
        "    if epoch % 20 == 0 :\n",
        "        print(log.format(epoch, train_acc, best_val_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrGpV8MHqCW3",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. GraphSAGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx_Ip5O3qE2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.nn import SAGEConv\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = SAGEConv(dataset.num_features, 16, normalize=True)\n",
        "        self.conv2 = SAGEConv(16, dataset.num_classes, normalize=True)\n",
        "\n",
        "        self.reg_params = self.conv1.parameters()\n",
        "        self.non_reg_params = self.conv2.parameters()\n",
        "\n",
        "    def forward(self):\n",
        "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index, edge_weight)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.reg_params, weight_decay=5e-4),\n",
        "    dict(params=model.non_reg_params, weight_decay=0)\n",
        "], lr=0.005)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "best_val_acc = test_acc = 0\n",
        "for epoch in range(1, 201):\n",
        "    train()\n",
        "    train_acc, val_acc, tmp_test_acc = test()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        test_acc = tmp_test_acc\n",
        "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
        "    if epoch % 20 == 0 :\n",
        "        print(log.format(epoch, train_acc, best_val_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7t2gW75qFTu",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. GAT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULFiieCjqGxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.nn import GATConv\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GATConv(dataset.num_features, 8, heads=8, dropout=0.6)\n",
        "        self.conv2 = GATConv(8 * 8, dataset.num_classes, heads=1, concat=True,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self):\n",
        "        x = F.dropout(data.x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, data.edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, data.edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "best_val_acc = test_acc = 0\n",
        "for epoch in range(1, 401):\n",
        "    train()\n",
        "    train_acc, val_acc, tmp_test_acc = test()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        test_acc = tmp_test_acc\n",
        "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
        "    if epoch % 20 == 0 :\n",
        "        print(log.format(epoch, train_acc, best_val_acc, test_acc))\n",
        "\n",
        "logits = model()\n",
        "pred = logits[data.test_mask]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
